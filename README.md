# tit4tat-AI

## 프로젝트 개요

본 프로젝트는 반복되는 죄수의 딜레마(Iterated Prisoner's Dilemma, IPD) 게임에서 다양한 전략 간의 상호작용을 분석하고, **강화학습 기반 전략**(예: Q-learning 기반 Tit-for-Tat)들이 **의사소통 오류(communication error)** 하에서도 얼마나 안정적으로 협력 관계를 유지할 수 있는지를 평가하는 것을 목표로 합니다.

## 목적

* Tit-for-Tat을 비롯한 다양한 전략이 **상대방의 의도를 잘못 해석할 가능성**이 있을 때 어떻게 행동하는지 측정
* \*\*의사 전달 오류율(10% \~ 90%)\*\*에 따른 전략 간 평균 점수 비교
* 강화학습을 통해 자가 적응하는 에이전트들이 **고정 전략보다 얼마나 유연한지** 검증

## 시뮬레이션 구성

### 전략 목록

| 전략 이름          | 설명                                  |
| -------------- | ----------------------------------- |
| `TFT_Agent`    | Q-learning으로 학습된 Tit-for-Tat 스타일 전략 |
| `QLearner_1`   | 일반 Q-learning 학습 기반 전략              |
| `Grim_Agent`   | 한 번 배신 당하면 영원히 배신                   |
| `AlwaysCoop`   | 항상 협력                               |
| `AlwaysDefect` | 항상 배신                               |
| `RandomAgent`  | 무작위로 협력 또는 배신 결정                    |

### 게임 설정

* 각 에이전트는 `400 epoch` 동안 학습
* 학습 후, 모든 에이전트 조합에 대해 `400 라운드`씩 게임 진행
* Noise(의사 전달 오류 확률)는 `0.1 ~ 0.9`까지 0.1 단위로 변화시킴
* 각 조합에 대한 평균 점수를 Heatmap으로 시각화

### 보상 테이블

|      | 상대: C | 상대: D |
| ---- | ----- | ----- |
| 나: C | (3,3) | (0,5) |
| 나: D | (5,0) | (1,1) |

## 실행 방법

1. 필요한 패키지를 설치합니다:

```bash
pip install numpy matplotlib
```

2. Python 스크립트를 실행합니다:

```bash
python main.py
```

3. 실행 결과로 다음을 얻을 수 있습니다:

   * 에이전트 학습 중 평균 점수 변화 그래프 (Match Index vs Avg Score)
   * 9개의 Heatmap (각기 다른 의사전달 오류율에서 전략 간 평균 점수)

## 주요 시각화 결과

* **Match Index 그래프**: 학습 중 평균 점수가 어떻게 수렴 또는 불안정해지는지 확인 가능
* **Heatmap**: 서로 다른 Noise 수준에서 전략 간 상호작용의 성과 시각화

## 해석

* 강화학습 기반 전략은 중간 수준까지의 noise (예: 10\~30%)에서는 협력 유지에 강인함
* Grim과 같은 전략은 작은 오해에도 쉽게 무너지며, 회복 불가
* AlwaysDefect는 Noise 수준에 관계 없이 높은 단기 이익을 추구하지만 장기적으론 평균 점수 낮음
* RandomAgent는 거의 항상 낮은 성과를 보임

## 확장 아이디어

* DQN 등 딥러닝 기반 전략 추가
* 상태 공간 확장 (최근 2\~3턴 기억 기반)
* 협력률, 배신률, 회복성 등 다양한 지표 추가
* 다양한 게임 환경 (Snowdrift, Stag Hunt 등) 적용 가능

## 참고 사항

* 본 시뮬레이션은 **의도하지 않은 배신**이 실제 협력 전략에서 얼마나 치명적일 수 있는지를 계량적으로 보여줍니다.
* 실험 결과는 전략 설계, 에이전트 의사결정 시스템, 다중 에이전트 시뮬레이션 등 여러 연구 분야에 응용될 수 있습니다.
